{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import saraRC1 as sara\n",
    "import saraRC1Old as sara_old\n",
    "\n",
    "seg_dim = 100\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranges = list(zip(np.arange(1, 7000, 500), np.arange(500, 7100, 500)))\n",
    "ranges = list(zip(np.arange(0, 2501, 500), np.arange(500, 2501, 500)))\n",
    "ranges = [list(t) for t in ranges]\n",
    "ranges[0][0] = 0\n",
    "# ranges[0][1] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './ASSR/images/test/'\n",
    "imgs = {}\n",
    "\n",
    "i = 0\n",
    "experiment = 1\n",
    "range_ = ranges[experiment - 1]\n",
    "\n",
    "for root, dirs, files in os.walk(img_path):\n",
    "    for file in files[range_[0]:range_[1]]:\n",
    "        file_name = file.split('.')[0]\n",
    "        imgs[file_name] = cv2.cvtColor(cv2.imread(os.path.join(root, file)), cv2.COLOR_BGR2RGB)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = './ASSR/gt/test/'\n",
    "# masks = {}\n",
    "gt_masks = {}\n",
    "gt_ranks = {}\n",
    "\n",
    "for file_name in imgs:\n",
    "    gt_ranks[file_name] = {}\n",
    "    \n",
    "    file = file_name + '.png'\n",
    "    mask = cv2.cvtColor(cv2.imread(os.path.join(mask_path, file)), cv2.COLOR_BGR2GRAY)\n",
    "    # masks[file_name] = cv2.cvtColor(cv2.imread(os.path.join(mask_path, file)), cv2.COLOR_BGR2GRAY)\n",
    "    # Separate the mask based on colour\n",
    "    # masks[file_name] = {}\n",
    "    gt_masks[file_name] = {}\n",
    "\n",
    "    # Detect different colours in mask\n",
    "    # Create histogram\n",
    "    hist = cv2.calcHist([mask], [0], None, [256], [0, 256])\n",
    "\n",
    "    # Show non-zero values and extract intensity values at that freq\n",
    "    non_zero = np.nonzero(hist)\n",
    "    x = non_zero[0][1:]\n",
    "\n",
    "    # Separate mask into regions which match the intensity values in x\n",
    "    for i, intensity in enumerate(reversed(x)):\n",
    "        # masks[file_name][i] = np.where(mask == intensity, 1, 0)\n",
    "        gt_masks[file_name][i] = np.where(mask == intensity, 1, 0)\n",
    "        \n",
    "        # Calculate ranks based on highest intensity\n",
    "        gt_ranks[file_name][i] = i + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MASK R-CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnntf2 import utils\n",
    "import mrcnntf2.model as modellib\n",
    "from mrcnntf2 import visualize\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     4\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GPU_IDS                        0\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 4\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = BATCH_SIZE\n",
    "    GPU_IDS = \"0\"\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n",
      "2.6.0\n",
      "3.1.0\n",
      "WARNING:tensorflow:From /home/matthewkenely/anaconda3/envs/sara/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import h5py\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(h5py.__version__)\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "\n",
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 of 104 complete\n",
      "Batch 2 of 104 complete\n",
      "Batch 3 of 104 complete\n",
      "Batch 4 of 104 complete\n",
      "Batch 5 of 104 complete\n",
      "Batch 6 of 104 complete\n",
      "Batch 7 of 104 complete\n",
      "Batch 8 of 104 complete\n",
      "Batch 9 of 104 complete\n",
      "Batch 10 of 104 complete\n",
      "Batch 11 of 104 complete\n",
      "Batch 12 of 104 complete\n",
      "Batch 13 of 104 complete\n",
      "Batch 14 of 104 complete\n",
      "Batch 15 of 104 complete\n",
      "Batch 16 of 104 complete\n",
      "Batch 17 of 104 complete\n",
      "Batch 18 of 104 complete\n",
      "Batch 19 of 104 complete\n",
      "Batch 20 of 104 complete\n",
      "Batch 21 of 104 complete\n",
      "Batch 22 of 104 complete\n",
      "Batch 23 of 104 complete\n",
      "Batch 24 of 104 complete\n",
      "Batch 25 of 104 complete\n",
      "Batch 26 of 104 complete\n",
      "Batch 27 of 104 complete\n",
      "Batch 28 of 104 complete\n",
      "Batch 29 of 104 complete\n",
      "Batch 30 of 104 complete\n",
      "Batch 31 of 104 complete\n",
      "Batch 32 of 104 complete\n",
      "Batch 33 of 104 complete\n",
      "Batch 34 of 104 complete\n",
      "Batch 35 of 104 complete\n",
      "Batch 36 of 104 complete\n",
      "Batch 37 of 104 complete\n",
      "Batch 38 of 104 complete\n",
      "Batch 39 of 104 complete\n",
      "Batch 40 of 104 complete\n",
      "Batch 41 of 104 complete\n",
      "Batch 42 of 104 complete\n",
      "Batch 43 of 104 complete\n",
      "Batch 44 of 104 complete\n",
      "Batch 45 of 104 complete\n",
      "Batch 46 of 104 complete\n",
      "Batch 47 of 104 complete\n",
      "Batch 48 of 104 complete\n",
      "Batch 49 of 104 complete\n",
      "Batch 50 of 104 complete\n",
      "Batch 51 of 104 complete\n",
      "Batch 52 of 104 complete\n",
      "Batch 53 of 104 complete\n",
      "Batch 54 of 104 complete\n",
      "Batch 55 of 104 complete\n",
      "Batch 56 of 104 complete\n",
      "Batch 57 of 104 complete\n",
      "Batch 58 of 104 complete\n",
      "Batch 59 of 104 complete\n",
      "Batch 60 of 104 complete\n",
      "Batch 61 of 104 complete\n",
      "Batch 62 of 104 complete\n",
      "Batch 63 of 104 complete\n",
      "Batch 64 of 104 complete\n",
      "Batch 65 of 104 complete\n",
      "Batch 66 of 104 complete\n",
      "Batch 67 of 104 complete\n",
      "Batch 68 of 104 complete\n",
      "Batch 69 of 104 complete\n",
      "Batch 70 of 104 complete\n",
      "Batch 71 of 104 complete\n",
      "Batch 72 of 104 complete\n",
      "Batch 73 of 104 complete\n",
      "Batch 74 of 104 complete\n",
      "Batch 75 of 104 complete\n",
      "Batch 76 of 104 complete\n",
      "Batch 77 of 104 complete\n",
      "Batch 78 of 104 complete\n",
      "Batch 79 of 104 complete\n",
      "Batch 80 of 104 complete\n",
      "Batch 81 of 104 complete\n",
      "Batch 82 of 104 complete\n",
      "Batch 83 of 104 complete\n",
      "Batch 84 of 104 complete\n",
      "Batch 85 of 104 complete\n",
      "Batch 86 of 104 complete\n",
      "Batch 87 of 104 complete\n",
      "Batch 88 of 104 complete\n",
      "Batch 89 of 104 complete\n",
      "Batch 90 of 104 complete\n",
      "Batch 91 of 104 complete\n",
      "Batch 92 of 104 complete\n",
      "Batch 93 of 104 complete\n",
      "Batch 94 of 104 complete\n",
      "Batch 95 of 104 complete\n",
      "Batch 96 of 104 complete\n",
      "Batch 97 of 104 complete\n",
      "Batch 98 of 104 complete\n",
      "Batch 99 of 104 complete\n",
      "Batch 100 of 104 complete\n",
      "Batch 101 of 104 complete\n",
      "Batch 102 of 104 complete\n",
      "Batch 103 of 104 complete\n",
      "Batch 104 of 104 complete\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "len(images) must be equal to BATCH_SIZE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8a56d7ee6fdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Run detection for the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Process the results for the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/Assignments/ICT3909 Final Year Project in Artificial Intelligence/ICT3909/optimisations/saliency-generator/mrcnntf2/model.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, images, verbose)\u001b[0m\n\u001b[1;32m   2513\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"inference\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Create model in inference mode.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2514\u001b[0m         assert len(\n\u001b[0;32m-> 2515\u001b[0;31m             images) == self.config.BATCH_SIZE, \"len(images) must be equal to BATCH_SIZE\"\n\u001b[0m\u001b[1;32m   2516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: len(images) must be equal to BATCH_SIZE"
     ]
    }
   ],
   "source": [
    "# Split the images into batches\n",
    "image_batches = [list(imgs.values())[i:i+BATCH_SIZE] for i in range(0, len(imgs), BATCH_SIZE)]\n",
    "\n",
    "\n",
    "masks = {}\n",
    "i = 0\n",
    "\n",
    "for batch in image_batches:\n",
    "    # Run detection for the current batch\n",
    "    results = model.detect(batch, verbose=0)\n",
    "    \n",
    "    # Process the results for the batch\n",
    "    for result in results:\n",
    "        file_name = list(imgs.keys())[i]\n",
    "        \n",
    "        # Visualize results for the current image in the batch\n",
    "        r = result\n",
    "        # visualize.display_instances(imgs[file_name], r['rois'], r['masks'], r['class_ids'], \n",
    "        #                             class_names, r['scores'])\n",
    "\n",
    "        masks[file_name] = {}\n",
    "\n",
    "        for j in range(len(r['class_ids'])):\n",
    "            masks[file_name][j] = np.array(r['masks'][:, :, j], dtype=np.uint8) * 255\n",
    "\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Batch {i // BATCH_SIZE} of {len(imgs) // BATCH_SIZE} complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-20d9e678c727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgt_ranks_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmasks_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mgt_masks_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'masks' is not defined"
     ]
    }
   ],
   "source": [
    "# Match masks generated by Mask RCNN to ground truth masks\n",
    "\n",
    "masks_valid = {}\n",
    "gt_masks_valid = {}\n",
    "gt_ranks_valid = {}\n",
    "\n",
    "for file_name in masks:\n",
    "    masks_valid[file_name] = {}\n",
    "    gt_masks_valid[file_name] = {}\n",
    "    gt_ranks_valid[file_name] = {}\n",
    "\n",
    "    for pred in masks[file_name]:\n",
    "        masks_valid[file_name][pred] = {}\n",
    "        gt_masks_valid[file_name][pred] = {}\n",
    "        gt_ranks_valid[file_name][pred] = {}\n",
    "\n",
    "        pred_mask = masks[file_name][pred]\n",
    "        \n",
    "        best_iou = 0\n",
    "\n",
    "        for gt in gt_masks[file_name]:\n",
    "            gt_mask = gt_masks[file_name][gt]\n",
    "\n",
    "            intersection = np.logical_and(pred_mask, gt_mask)\n",
    "            union = np.logical_or(pred_mask, gt_mask)\n",
    "            iou_score = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "            if iou_score > best_iou:\n",
    "                best_iou = iou_score\n",
    "                best_gt = gt\n",
    "\n",
    "        if best_iou > 0.3:\n",
    "            masks_valid[file_name][pred] = pred_mask\n",
    "            gt_masks_valid[file_name][pred] = gt_masks[file_name][best_gt]\n",
    "            gt_ranks_valid[file_name][pred] = gt_ranks[file_name][best_gt]\n",
    "        else:\n",
    "            del masks_valid[file_name][pred]\n",
    "            del gt_masks_valid[file_name][pred]\n",
    "            del gt_ranks_valid[file_name][pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fc845a01ae45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of masks before deletion: {count_keys(masks)}\\nNumber of masks after deletion: {count_keys(masks_valid)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'masks' is not defined"
     ]
    }
   ],
   "source": [
    "# Number of non-empty keys in masks\n",
    "def count_keys(masks):\n",
    "    count = 0\n",
    "    for file_name in masks:\n",
    "        if len(masks[file_name]) > 0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "print(f'Number of masks before deletion: {count_keys(masks)}\\nNumber of masks after deletion: {count_keys(masks_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks before deletion: 5127\n",
      "Number of masks after deletion: 1576\n"
     ]
    }
   ],
   "source": [
    "# Count number of masks before and after recursively (check values, not keys)\n",
    "def count_masks(masks):\n",
    "    count = 0\n",
    "    for file_name in masks:\n",
    "        count += len(masks[file_name])\n",
    "    return count\n",
    "\n",
    "print(f'Number of masks before deletion: {count_masks(masks)}\\nNumber of masks after deletion: {count_masks(masks_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = masks_valid\n",
    "gt_masks = gt_masks_valid\n",
    "gt_ranks = gt_ranks_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to .h5\n",
    "import h5py\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/masks_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in masks:\n",
    "        for mask in masks[file_name]:\n",
    "            hf.create_dataset(f'{file_name}/{mask}', data=masks[file_name][mask])\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/gt_masks_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in gt_masks:\n",
    "        for mask in gt_masks[file_name]:\n",
    "            hf.create_dataset(f'{file_name}/{mask}', data=gt_masks[file_name][mask])\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/gt_ranks_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in gt_ranks:\n",
    "        gt_ranks[file_name] = np.array(list(gt_ranks[file_name].values()))\n",
    "        hf.create_dataset(f'{file_name}', data=gt_ranks[file_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from .h5\n",
    "import h5py\n",
    "\n",
    "masks = {}\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/masks_' + str(experiment) + '.h5', 'r') as hf:\n",
    "    for file_name in hf:\n",
    "        masks[file_name] = {}\n",
    "        for mask in hf[file_name]:\n",
    "            masks[file_name][mask] = hf[f'{file_name}/{mask}'][:]\n",
    "\n",
    "gt_masks = {}\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/gt_masks_' + str(experiment) + '.h5', 'r') as hf:\n",
    "    for file_name in hf:\n",
    "        gt_masks[file_name] = {}\n",
    "        for mask in hf[file_name]:\n",
    "            gt_masks[file_name][mask] = hf[f'{file_name}/{mask}'][:]\n",
    "\n",
    "gt_ranks = {}\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/gt_ranks_' + str(experiment) + '.h5', 'r') as hf:\n",
    "    for file_name in hf:\n",
    "        gt_ranks[file_name] = hf[file_name][:]\n",
    "\n",
    "        # Convert list into dict with keys as integers\n",
    "        gt_ranks[file_name] = {i: rank for i, rank in enumerate(gt_ranks[file_name])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saliency Maps/Heatmaps/Rankings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DeepGaze IIE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/matthewkenely/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "Using cache found in /home/matthewkenely/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "/home/matthewkenely/Programming/Assignments/ICT3909 Final Year Project in Artificial Intelligence/ICT3909/optimisations/saliency-generator/saraRC1.py:198: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  image_batch = torch.tensor([img.transpose(2, 0, 1) for img in images]).to(DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 of 63 complete\n",
      "Batch 2 of 63 complete\n",
      "Batch 3 of 63 complete\n",
      "Batch 4 of 63 complete\n",
      "Batch 5 of 63 complete\n",
      "Batch 6 of 63 complete\n",
      "Batch 7 of 63 complete\n",
      "Batch 8 of 63 complete\n",
      "Batch 9 of 63 complete\n",
      "Batch 10 of 63 complete\n",
      "Batch 11 of 63 complete\n",
      "Batch 12 of 63 complete\n",
      "Batch 13 of 63 complete\n",
      "Batch 14 of 63 complete\n",
      "Batch 15 of 63 complete\n",
      "Batch 16 of 63 complete\n",
      "Batch 17 of 63 complete\n",
      "Batch 18 of 63 complete\n",
      "Batch 19 of 63 complete\n",
      "Batch 20 of 63 complete\n",
      "Batch 21 of 63 complete\n",
      "Batch 22 of 63 complete\n",
      "Batch 23 of 63 complete\n",
      "Batch 24 of 63 complete\n",
      "Batch 25 of 63 complete\n",
      "Batch 26 of 63 complete\n",
      "Batch 27 of 63 complete\n",
      "Batch 28 of 63 complete\n",
      "Batch 29 of 63 complete\n",
      "Batch 30 of 63 complete\n",
      "Batch 31 of 63 complete\n",
      "Batch 32 of 63 complete\n",
      "Batch 33 of 63 complete\n",
      "Batch 34 of 63 complete\n",
      "Batch 35 of 63 complete\n",
      "Batch 36 of 63 complete\n",
      "Batch 37 of 63 complete\n",
      "Batch 38 of 63 complete\n",
      "Batch 39 of 63 complete\n",
      "Batch 40 of 63 complete\n",
      "Batch 41 of 63 complete\n",
      "Batch 42 of 63 complete\n",
      "Batch 43 of 63 complete\n",
      "Batch 44 of 63 complete\n",
      "Batch 45 of 63 complete\n",
      "Batch 46 of 63 complete\n",
      "Batch 47 of 63 complete\n",
      "Batch 48 of 63 complete\n",
      "Batch 49 of 63 complete\n",
      "Batch 50 of 63 complete\n",
      "Batch 51 of 63 complete\n",
      "Batch 52 of 63 complete\n",
      "Batch 53 of 63 complete\n",
      "Batch 54 of 63 complete\n",
      "Batch 55 of 63 complete\n",
      "Batch 56 of 63 complete\n",
      "Batch 57 of 63 complete\n",
      "Batch 58 of 63 complete\n",
      "Batch 59 of 63 complete\n",
      "Batch 60 of 63 complete\n",
      "Batch 61 of 63 complete\n",
      "Batch 62 of 63 complete\n",
      "Batch 63 of 63 complete\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import deepgaze_pytorch\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = [20, 10]\n",
    "# plt.figure()\n",
    "# plt.tight_layout()\n",
    "\n",
    "generators = ['deepgaze']\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "DEVICE = 'cuda'  # Use GPU if available\n",
    "model = deepgaze_pytorch.DeepGazeIIE(pretrained=True).to(DEVICE)\n",
    "\n",
    "# Split the images with masks into batches with the image names as keys and the images as values\n",
    "image_batches = [{k: imgs[k] for k in list(masks.keys())[i:i+BATCH_SIZE]} for i in range(0, len(masks), BATCH_SIZE)]\n",
    "\n",
    "# seg_dim = 9\n",
    "saliency_maps = {}\n",
    "sara_heatmaps = {}\n",
    "sara_lists = {}\n",
    "\n",
    "sara.WEIGHTS = (1, 1, 0, 1)\n",
    "\n",
    "c = 0\n",
    "total = 0\n",
    "\n",
    "for batch in image_batches:\n",
    "    start = time()\n",
    "\n",
    "    for im in batch:\n",
    "        if im not in saliency_maps:\n",
    "            saliency_maps[im] = {}\n",
    "            sara_heatmaps[im] = {}\n",
    "            sara_lists[im] = {}\n",
    "\n",
    "    for generator in generators:\n",
    "        temp_saliency_maps = sara.return_saliency_batch(batch.values(), generator=generator, deepgaze_model=model, DEVICE=DEVICE, BATCH_SIZE=BATCH_SIZE)\n",
    "        \n",
    "    sara.reset()\n",
    "    sara.WEIGHTS = (1, 1, 0, 1)\n",
    "\n",
    "    for i, im in enumerate(batch):\n",
    "        saliency_maps[im][generator] = temp_saliency_maps[i]\n",
    "        # plt.figure()\n",
    "        # plt.imshow(temp_saliency_maps[i])\n",
    "        # plt.show()\n",
    "        sara_heatmaps[im][generator], sara_lists[im][generator] = sara.return_sara(cv2.cvtColor(imgs[im].copy(), cv2.COLOR_RGB2BGR), seg_dim, saliency_map=saliency_maps[im][generator])\n",
    "        # print(sara_lists[im][generator])\n",
    "        # plt.figure()\n",
    "        # plt.subplot(121)\n",
    "        # plt.imshow(saliency_maps[im][generator], cmap='gray')\n",
    "        # plt.subplot(122)\n",
    "        # plt.imshow(cv2.cvtColor(sara_heatmaps[im][generator], cv2.COLOR_BGR2RGB))\n",
    "        # plt.show()\n",
    "        sara.reset()\n",
    "        sara.WEIGHTS = (1, 1, 0, 1)\n",
    "\n",
    "    c += 1\n",
    "\n",
    "    print(f'Batch {c} of {len(image_batches)} complete')\n",
    "\n",
    "    # total += time() - start\n",
    "    # average = total / c\n",
    "\n",
    "\n",
    "    # if c == 5:\n",
    "    #     print(f'Segdim: {seg_dim} Average time per batch: {average} per image: {average / BATCH_SIZE}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Old SaRa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time\n",
    "# import deepgaze_pytorch\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "plt.figure()\n",
    "plt.tight_layout()\n",
    "\n",
    "generators = ['itti']\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "DEVICE = 'cpu'  # Use GPU if available\n",
    "# model = deepgaze_pytorch.DeepGazeIIE(pretrained=True).to(DEVICE)\n",
    "\n",
    "# Split the images with masks into batches with the image names as keys and the images as values\n",
    "# image_batches = [{k: imgs[k] for k in list(masks.keys())[i:i+BATCH_SIZE]} for i in range(0, len(masks), BATCH_SIZE)]\n",
    "\n",
    "seg_dim = 15\n",
    "saliency_maps = {}\n",
    "sara_heatmaps = {}\n",
    "sara_lists = {}\n",
    "\n",
    "sara.WEIGHTS = (1, 1, 0, 1)\n",
    "\n",
    "c = 0\n",
    "\n",
    "for im in imgs:\n",
    "    start = time()\n",
    "\n",
    "    if im not in saliency_maps:\n",
    "        saliency_maps[im] = {}\n",
    "        sara_heatmaps[im] = {}\n",
    "        sara_lists[im] = {}\n",
    "\n",
    "    for generator in generators:\n",
    "        # saliency_maps[im][generator] = sara.return_saliency(imgs[im], generator=generator)\n",
    "        # sara_heatmaps[im][generator], sara_lists[im][generator] = sara.return_sara(cv2.cvtColor(imgs[im].copy(), cv2.COLOR_RGB2BGR), seg_dim, saliency_map=saliency_maps[im][generator])\n",
    "        # sara_heatmaps[im][generator], sara_lists[im][generator] = sara_old.returnSARA(cv2.cvtColor(imgs[im].copy(), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # sara_heatmaps[im][generator], sara_lists[im][generator] = sara_old.returnSARA(cv2.cvtColor(imgs[im].copy(), cv2.COLOR_RGB2BGR))\n",
    "        sara_heatmaps[im][generator], sara_lists[im][generator] = sara.return_sara(cv2.cvtColor(imgs[im].copy(), cv2.COLOR_RGB2BGR), seg_dim)\n",
    "        # print(sara_lists[im][generator])\n",
    "\n",
    "\n",
    "    c += 1\n",
    "\n",
    "    # print(f'Image {c} of {len(imgs)} complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = False\n",
    "\n",
    "if old:\n",
    "    subdirectory = 'old'\n",
    "else:\n",
    "    subdirectory = 'new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to .h5\n",
    "import h5py\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/saliency_maps_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in saliency_maps:\n",
    "        for generator in saliency_maps[file_name]:\n",
    "            hf.create_dataset(f'{file_name}/{generator}', data=saliency_maps[file_name][generator])\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sara_heatmaps_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in sara_heatmaps:\n",
    "        for generator in sara_heatmaps[file_name]:\n",
    "            hf.create_dataset(f'{file_name}/{generator}', data=sara_heatmaps[file_name][generator])\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sara_lists_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in sara_lists:\n",
    "        for generator in sara_lists[file_name]:\n",
    "            hf.create_dataset(f'{file_name}/{generator}', data=sara_lists[file_name][generator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load from .h5\n",
    "# import h5py\n",
    "\n",
    "# saliency_maps = {}\n",
    "\n",
    "# with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/saliency_maps_' + str(experiment) + '.h5', 'r') as hf:\n",
    "#     for file_name in hf:\n",
    "#         saliency_maps[file_name] = {}\n",
    "#         for generator in hf[file_name]:\n",
    "#             saliency_maps[file_name][generator] = hf[f'{file_name}/{generator}'][:]\n",
    "\n",
    "# sara_heatmaps = {}\n",
    "\n",
    "# with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sara_heatmaps_' + str(experiment) + '.h5', 'r') as hf:\n",
    "#     for file_name in hf:\n",
    "#         sara_heatmaps[file_name] = {}\n",
    "#         for generator in hf[file_name]:\n",
    "#             sara_heatmaps[file_name][generator] = hf[f'{file_name}/{generator}'][:]\n",
    "\n",
    "# sara_lists = {}\n",
    "\n",
    "# with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sara_lists_' + str(experiment) + '.h5', 'r') as hf:\n",
    "#     for file_name in hf:\n",
    "#         sara_lists[file_name] = {}\n",
    "#         for generator in hf[file_name]:\n",
    "#             sara_lists[file_name][generator] = hf[f'{file_name}/{generator}'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Mask Ranking</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_coordinates(index, seg_dim, im_size):\n",
    "    '''\n",
    "    Given an index and a shape, this function returns the corresponding coordinates.\n",
    "    '''\n",
    "\n",
    "    x1 = int((index % seg_dim) * (im_size[1] / seg_dim))\n",
    "    y1 = int((index // seg_dim) * (im_size[0] / seg_dim))\n",
    "\n",
    "    x2 = int(x1 + (im_size[1] / seg_dim))\n",
    "    y2 = int(y1 + (im_size[0] / seg_dim))\n",
    "    \n",
    "    return (x1, y1, x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each segment, check which mask falls under that segment using MRn = rank(Gi); (Gi interesect Mn) > T\n",
    "mask_segments = {}\n",
    "\n",
    "if old:\n",
    "    generator = 'itti'\n",
    "else:\n",
    "    generator = 'deepgaze'\n",
    "    \n",
    "\n",
    "for sara_list in sara_lists:\n",
    "    for segment in sara_lists[sara_list][generator]:\n",
    "        if sara_list not in mask_segments:\n",
    "            mask_segments[sara_list] = {}\n",
    "\n",
    "        # Convert index to coordinates, extract segment from heatmap\n",
    "        shape = sara_heatmaps[sara_list][generator].shape[0:2]\n",
    "        x1, y1, x2, y2 = index_to_coordinates(segment[0], seg_dim, shape)\n",
    "\n",
    "        # print(x1, y1, x2, y2)\n",
    "\n",
    "        if sara_list in list(masks.keys()):\n",
    "            # Find the best matching mask\n",
    "            best_iou = 0\n",
    "            best_mask = None\n",
    "            \n",
    "            for m in masks[sara_list]:\n",
    "                if m not in mask_segments[sara_list]:\n",
    "                    mask_segments[sara_list][m] = []\n",
    "\n",
    "                # Extract mask from masks\n",
    "                mask = masks[sara_list][m][y1:y2, x1:x2]\n",
    "\n",
    "                # Calculate intersection over union\n",
    "                intersection = np.sum(mask > 0)\n",
    "                union = np.sum(mask > 0) + np.sum(mask == 0)\n",
    "                iou = intersection / union\n",
    "\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_mask = m\n",
    "                elif iou > 0:\n",
    "                    mask_segments[sara_list][m].append(segment)\n",
    "\n",
    "            if best_mask is not None:\n",
    "                mask_segments[sara_list][best_mask].append(segment)\n",
    "\n",
    "\n",
    "            # Check the masks which are not best_mask, if they will not be empty after removing the current segment, do so\n",
    "            for m in mask_segments[sara_list]:\n",
    "                if m != best_mask:\n",
    "                    if len(mask_segments[sara_list][m]) > 1:\n",
    "                        mask_segments[sara_list][m].pop()\n",
    "\n",
    "        # Sort mask_segments[sara_list]\n",
    "\n",
    "\n",
    "    # If there are empty masks, remove them and remove the corresponding mask in gt_ranks and gt_masks\n",
    "    for m in list(mask_segments[sara_list].keys()):\n",
    "        if len(mask_segments[sara_list][m]) == 0:\n",
    "            del mask_segments[sara_list][m]\n",
    "            del gt_masks[sara_list][m]\n",
    "\n",
    "            # Find index of key\n",
    "            for i, key in enumerate(gt_ranks[sara_list]):\n",
    "                if key == m:\n",
    "                    break\n",
    "            # del gt_ranks[sara_list][i]\n",
    "            gt_ranks[sara_list].pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each mask, find the average rank of the segments\n",
    "mask_segments_min = {}\n",
    "\n",
    "for sara_list in mask_segments:\n",
    "    for m in mask_segments[sara_list]:\n",
    "        # mask_segments_min[sara_list][m] = min(mask_segments[sara_list][m], key=lambda x: x[1])[0]\n",
    "        if sara_list not in mask_segments_min:\n",
    "            mask_segments_min[sara_list] = {}\n",
    "        \n",
    "        # mask_segments_min[sara_list][m] = min(mask_segments[sara_list][m], key=lambda x: x[1])\n",
    "        mask_segments_min[sara_list][m] = np.min([seg[1] for seg in mask_segments[sara_list][m]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ranks = {}\n",
    "\n",
    "for sara_list in mask_segments_min:\n",
    "    mask_ranks[sara_list] = {}\n",
    "\n",
    "    sorted_ranks = sorted(mask_segments_min[sara_list].items(), key=lambda x: x[1])\n",
    "    # sorted_ranks = sorted(mask_segments_min[sara_list].items(), key=lambda x: x[1][1])\n",
    "\n",
    "\n",
    "    for i in range(len(sorted_ranks)):\n",
    "        mask_ranks[sara_list][sorted_ranks[i][0]] = i\n",
    "\n",
    "    # Sort mask_ranks[sara_list] by object\n",
    "    mask_ranks[sara_list] = {k: v for k, v in sorted(mask_ranks[sara_list].items(), key=lambda item: item[0])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Spearman Correlation (Metric for Ranks)</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_spr(spr_value):\n",
    "    r_min = -1\n",
    "    r_max = 1\n",
    "\n",
    "    norm_spr = (spr_value - r_min) / (r_max - r_min)\n",
    "\n",
    "    return norm_spr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthewkenely/anaconda3/envs/sara/lib/python3.6/site-packages/scipy/stats/stats.py:4196: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SOR: 0.7507936316597129\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as sc\n",
    "\n",
    "all_spr = []\n",
    "\n",
    "for sara_list in mask_ranks:\n",
    "    # print(f'PR: {list(mask_ranks[sara_list].values())}\\nGT: {list(gt_ranks[sara_list].values())}')\n",
    "    spr = sc.spearmanr(list(mask_ranks[sara_list].values()), list(gt_ranks[sara_list].values())[:len(list(mask_ranks[sara_list].values()))])\n",
    "    if not np.isnan(spr.correlation):\n",
    "        all_spr.append(get_norm_spr(spr.correlation))\n",
    "\n",
    "print(f'Average SOR: {np.mean(all_spr)}')\n",
    "\n",
    "# Plot sprs\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(all_spr, marker='o', linestyle='None')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_spr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary: image: spr\n",
    "sprs = {}\n",
    "\n",
    "for sara_list in mask_ranks:\n",
    "    spr = sc.spearmanr(list(mask_ranks[sara_list].values()), list(gt_ranks[sara_list].values())[:len(list(mask_ranks[sara_list].values()))])\n",
    "    if not np.isnan(spr.correlation):\n",
    "        sprs[sara_list] = get_norm_spr(spr.correlation)\n",
    "\n",
    "# Sort sprs by value descending\n",
    "sprs = {k: v for k, v in sorted(sprs.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "len_ = len(all_spr)\n",
    "\n",
    "# Save len_ in txt file\n",
    "with open('./experiments/' + str(experiment) + '/len_' + str(experiment) + '.txt', 'w') as f:\n",
    "    f.write(str(len_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all sprs with value > 0.7\n",
    "sprs_07 = {k: v for k, v in sprs.items() if v > 0.7}\n",
    "\n",
    "for sara_list in mask_segments_min:\n",
    "    mask_ranks[sara_list] = {}\n",
    "    # Extract the ranks and sort them by the third value in each tuple\n",
    "    sorted_ranks = sorted(mask_segments_min[sara_list].items(), key=lambda x: x[1][1])\n",
    "\n",
    "    for i in range(len(sorted_ranks)):\n",
    "        mask_ranks[sara_list][sorted_ranks[i][0]] = i\n",
    "\n",
    "    # Sort mask_ranks[sara_list] by object\n",
    "    mask_ranks[sara_list] = {k: v for k, v in sorted(mask_ranks[sara_list].items(), key=lambda item: item[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to .h5\n",
    "import h5py\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sprs_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in sprs:\n",
    "        hf.create_dataset(f'{file_name}', data=sprs[file_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load from .h5\n",
    "# import h5py\n",
    "\n",
    "# sprs = {}\n",
    "\n",
    "# with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sprs_' + str(experiment) + '.h5', 'r') as hf:\n",
    "#     for file_name in hf:\n",
    "#         sprs[file_name] = hf[file_name][:]\n",
    "\n",
    "#         # Convert list into dict with keys as integers\n",
    "#         sprs[file_name] = {i: spr for i, spr in enumerate(sprs[file_name])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Mean Absolute Error</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(pred, gt):\n",
    "    return np.mean(np.abs(pred - gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b473009bae15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msara_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '2'"
     ]
    }
   ],
   "source": [
    "all_mae = 0\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "for sara_list in masks:\n",
    "    for mask in masks[sara_list]:\n",
    "        # print(masks[sara_list][mask] - gt_masks[sara_list][mask])\n",
    "        pred = masks[sara_list][mask]\n",
    "        pred = np.array(pred, dtype=np.uint8)\n",
    "        pred = cv2.threshold(pred, 0.5, 1, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        gt = gt_masks[sara_list][mask]\n",
    "        gt = np.array(gt, dtype=np.uint8)\n",
    "        gt = cv2.threshold(gt, 0.5, 1, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        temp_mae = mae(pred, gt)\n",
    "\n",
    "        # Print iou\n",
    "        intersection = np.logical_and(pred, gt)\n",
    "        union = np.logical_or(pred, gt)\n",
    "        iou_score = np.sum(intersection) / np.sum(union)\n",
    "        # print(f'IOU: {iou_score}')\n",
    "\n",
    "        # plt.figure()\n",
    "        # plt.subplot(131)\n",
    "        # plt.imshow(pred)\n",
    "        # plt.subplot(132)\n",
    "        # plt.imshow(gt)\n",
    "        # plt.subplot(133)\n",
    "        # plt.imshow(pred - gt)\n",
    "        # plt.show()\n",
    "        all_mae += temp_mae\n",
    "        # print()\n",
    "        # break\n",
    "\n",
    "print(f'Average /mae: {all_mae / len(masks)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('coco')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8985379cc137063dd0de237b7b7b8346889aff6edaf8a0ed61b320fa88bc9a9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

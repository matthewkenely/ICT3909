{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import saraRC1 as sara\n",
    "import saraRC1Old as sara_old\n",
    "\n",
    "seg_dim = 9\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranges = list(zip(np.arange(1, 7000, 500), np.arange(500, 7100, 500)))\n",
    "ranges = list(zip(np.arange(0, 2501, 500), np.arange(500, 2501, 500)))\n",
    "ranges = [list(t) for t in ranges]\n",
    "ranges[0][0] = 0\n",
    "# ranges[0][1] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './ASSR/images/test/'\n",
    "imgs = {}\n",
    "\n",
    "i = 0\n",
    "experiment = 2\n",
    "range_ = ranges[experiment - 1]\n",
    "\n",
    "for root, dirs, files in os.walk(img_path):\n",
    "    for file in files[range_[0]:range_[1]]:\n",
    "        file_name = file.split('.')[0]\n",
    "        imgs[file_name] = cv2.cvtColor(cv2.imread(os.path.join(root, file)), cv2.COLOR_BGR2RGB)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = './ASSR/gt/test/'\n",
    "# masks = {}\n",
    "gt_masks = {}\n",
    "gt_ranks = {}\n",
    "\n",
    "for file_name in imgs:\n",
    "    gt_ranks[file_name] = {}\n",
    "    \n",
    "    file = file_name + '.png'\n",
    "    mask = cv2.cvtColor(cv2.imread(os.path.join(mask_path, file)), cv2.COLOR_BGR2GRAY)\n",
    "    # masks[file_name] = cv2.cvtColor(cv2.imread(os.path.join(mask_path, file)), cv2.COLOR_BGR2GRAY)\n",
    "    # Separate the mask based on colour\n",
    "    # masks[file_name] = {}\n",
    "    gt_masks[file_name] = {}\n",
    "\n",
    "    # Detect different colours in mask\n",
    "    # Create histogram\n",
    "    hist = cv2.calcHist([mask], [0], None, [256], [0, 256])\n",
    "\n",
    "    # Show non-zero values and extract intensity values at that freq\n",
    "    non_zero = np.nonzero(hist)\n",
    "    x = non_zero[0][1:]\n",
    "\n",
    "    # Separate mask into regions which match the intensity values in x\n",
    "    for i, intensity in enumerate(reversed(x)):\n",
    "        # masks[file_name][i] = np.where(mask == intensity, 1, 0)\n",
    "        gt_masks[file_name][i] = np.where(mask == intensity, 1, 0)\n",
    "        \n",
    "        # Calculate ranks based on highest intensity\n",
    "        gt_ranks[file_name][i] = i + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MASK R-CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnntf2 import utils\n",
    "import mrcnntf2.model as modellib\n",
    "from mrcnntf2 import visualize\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     4\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GPU_IDS                        0\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 4\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = BATCH_SIZE\n",
    "    GPU_IDS = \"0\"\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n",
      "2.6.0\n",
      "3.1.0\n",
      "WARNING:tensorflow:From /home/matthewkenely/anaconda3/envs/sara/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import h5py\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(h5py.__version__)\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "\n",
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 of 125 complete\n",
      "Batch 2 of 125 complete\n",
      "Batch 3 of 125 complete\n",
      "Batch 4 of 125 complete\n",
      "Batch 5 of 125 complete\n",
      "Batch 6 of 125 complete\n",
      "Batch 7 of 125 complete\n",
      "Batch 8 of 125 complete\n",
      "Batch 9 of 125 complete\n",
      "Batch 10 of 125 complete\n",
      "Batch 11 of 125 complete\n",
      "Batch 12 of 125 complete\n",
      "Batch 13 of 125 complete\n",
      "Batch 14 of 125 complete\n",
      "Batch 15 of 125 complete\n",
      "Batch 16 of 125 complete\n",
      "Batch 17 of 125 complete\n",
      "Batch 18 of 125 complete\n",
      "Batch 19 of 125 complete\n",
      "Batch 20 of 125 complete\n",
      "Batch 21 of 125 complete\n",
      "Batch 22 of 125 complete\n",
      "Batch 23 of 125 complete\n",
      "Batch 24 of 125 complete\n",
      "Batch 25 of 125 complete\n",
      "Batch 26 of 125 complete\n",
      "Batch 27 of 125 complete\n",
      "Batch 28 of 125 complete\n",
      "Batch 29 of 125 complete\n",
      "Batch 30 of 125 complete\n",
      "Batch 31 of 125 complete\n",
      "Batch 32 of 125 complete\n",
      "Batch 33 of 125 complete\n",
      "Batch 34 of 125 complete\n",
      "Batch 35 of 125 complete\n",
      "Batch 36 of 125 complete\n",
      "Batch 37 of 125 complete\n",
      "Batch 38 of 125 complete\n",
      "Batch 39 of 125 complete\n",
      "Batch 40 of 125 complete\n",
      "Batch 41 of 125 complete\n",
      "Batch 42 of 125 complete\n",
      "Batch 43 of 125 complete\n",
      "Batch 44 of 125 complete\n",
      "Batch 45 of 125 complete\n",
      "Batch 46 of 125 complete\n",
      "Batch 47 of 125 complete\n",
      "Batch 48 of 125 complete\n",
      "Batch 49 of 125 complete\n",
      "Batch 50 of 125 complete\n",
      "Batch 51 of 125 complete\n",
      "Batch 52 of 125 complete\n",
      "Batch 53 of 125 complete\n",
      "Batch 54 of 125 complete\n",
      "Batch 55 of 125 complete\n",
      "Batch 56 of 125 complete\n",
      "Batch 57 of 125 complete\n",
      "Batch 58 of 125 complete\n",
      "Batch 59 of 125 complete\n",
      "Batch 60 of 125 complete\n",
      "Batch 61 of 125 complete\n",
      "Batch 62 of 125 complete\n",
      "Batch 63 of 125 complete\n",
      "Batch 64 of 125 complete\n",
      "Batch 65 of 125 complete\n",
      "Batch 66 of 125 complete\n",
      "Batch 67 of 125 complete\n",
      "Batch 68 of 125 complete\n",
      "Batch 69 of 125 complete\n",
      "Batch 70 of 125 complete\n",
      "Batch 71 of 125 complete\n",
      "Batch 72 of 125 complete\n",
      "Batch 73 of 125 complete\n",
      "Batch 74 of 125 complete\n",
      "Batch 75 of 125 complete\n",
      "Batch 76 of 125 complete\n",
      "Batch 77 of 125 complete\n",
      "Batch 78 of 125 complete\n",
      "Batch 79 of 125 complete\n",
      "Batch 80 of 125 complete\n",
      "Batch 81 of 125 complete\n",
      "Batch 82 of 125 complete\n",
      "Batch 83 of 125 complete\n",
      "Batch 84 of 125 complete\n",
      "Batch 85 of 125 complete\n",
      "Batch 86 of 125 complete\n",
      "Batch 87 of 125 complete\n",
      "Batch 88 of 125 complete\n",
      "Batch 89 of 125 complete\n",
      "Batch 90 of 125 complete\n",
      "Batch 91 of 125 complete\n",
      "Batch 92 of 125 complete\n",
      "Batch 93 of 125 complete\n",
      "Batch 94 of 125 complete\n",
      "Batch 95 of 125 complete\n",
      "Batch 96 of 125 complete\n",
      "Batch 97 of 125 complete\n",
      "Batch 98 of 125 complete\n",
      "Batch 99 of 125 complete\n",
      "Batch 100 of 125 complete\n",
      "Batch 101 of 125 complete\n",
      "Batch 102 of 125 complete\n",
      "Batch 103 of 125 complete\n",
      "Batch 104 of 125 complete\n",
      "Batch 105 of 125 complete\n",
      "Batch 106 of 125 complete\n",
      "Batch 107 of 125 complete\n",
      "Batch 108 of 125 complete\n",
      "Batch 109 of 125 complete\n",
      "Batch 110 of 125 complete\n",
      "Batch 111 of 125 complete\n",
      "Batch 112 of 125 complete\n",
      "Batch 113 of 125 complete\n",
      "Batch 114 of 125 complete\n",
      "Batch 115 of 125 complete\n",
      "Batch 116 of 125 complete\n",
      "Batch 117 of 125 complete\n",
      "Batch 118 of 125 complete\n",
      "Batch 119 of 125 complete\n",
      "Batch 120 of 125 complete\n",
      "Batch 121 of 125 complete\n",
      "Batch 122 of 125 complete\n",
      "Batch 123 of 125 complete\n",
      "Batch 124 of 125 complete\n",
      "Batch 125 of 125 complete\n"
     ]
    }
   ],
   "source": [
    "# Split the images into batches\n",
    "image_batches = [list(imgs.values())[i:i+BATCH_SIZE] for i in range(0, len(imgs), BATCH_SIZE)]\n",
    "\n",
    "\n",
    "masks = {}\n",
    "i = 0\n",
    "\n",
    "for batch in image_batches:\n",
    "    # Run detection for the current batch\n",
    "    results = model.detect(batch, verbose=0)\n",
    "    \n",
    "    # Process the results for the batch\n",
    "    for result in results:\n",
    "        file_name = list(imgs.keys())[i]\n",
    "        \n",
    "        # Visualize results for the current image in the batch\n",
    "        r = result\n",
    "        # visualize.display_instances(imgs[file_name], r['rois'], r['masks'], r['class_ids'], \n",
    "        #                             class_names, r['scores'])\n",
    "\n",
    "        masks[file_name] = {}\n",
    "\n",
    "        for j in range(len(r['class_ids'])):\n",
    "            masks[file_name][j] = np.array(r['masks'][:, :, j], dtype=np.uint8) * 255\n",
    "\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Batch {i // BATCH_SIZE} of {len(imgs) // BATCH_SIZE} complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match masks generated by Mask RCNN to ground truth masks\n",
    "\n",
    "masks_valid = {}\n",
    "gt_masks_valid = {}\n",
    "gt_ranks_valid = {}\n",
    "\n",
    "for file_name in masks:\n",
    "    masks_valid[file_name] = {}\n",
    "    gt_masks_valid[file_name] = {}\n",
    "    gt_ranks_valid[file_name] = {}\n",
    "\n",
    "    for pred in masks[file_name]:\n",
    "        masks_valid[file_name][pred] = {}\n",
    "        gt_masks_valid[file_name][pred] = {}\n",
    "        gt_ranks_valid[file_name][pred] = {}\n",
    "\n",
    "        pred_mask = masks[file_name][pred]\n",
    "        \n",
    "        best_iou = 0\n",
    "\n",
    "        for gt in gt_masks[file_name]:\n",
    "            gt_mask = gt_masks[file_name][gt]\n",
    "\n",
    "            intersection = np.logical_and(pred_mask, gt_mask)\n",
    "            union = np.logical_or(pred_mask, gt_mask)\n",
    "            iou_score = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "            if iou_score > best_iou:\n",
    "                best_iou = iou_score\n",
    "                best_gt = gt\n",
    "\n",
    "        if best_iou > 0.3:\n",
    "            masks_valid[file_name][pred] = pred_mask\n",
    "            gt_masks_valid[file_name][pred] = gt_masks[file_name][best_gt]\n",
    "            gt_ranks_valid[file_name][pred] = gt_ranks[file_name][best_gt]\n",
    "        else:\n",
    "            del masks_valid[file_name][pred]\n",
    "            del gt_masks_valid[file_name][pred]\n",
    "            del gt_ranks_valid[file_name][pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks before deletion: 499\n",
      "Number of masks after deletion: 499\n"
     ]
    }
   ],
   "source": [
    "# Number of non-empty keys in masks\n",
    "def count_keys(masks):\n",
    "    count = 0\n",
    "    for file_name in masks:\n",
    "        if len(masks[file_name]) > 0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "print(f'Number of masks before deletion: {count_keys(masks)}\\nNumber of masks after deletion: {count_keys(masks_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks before deletion: 1900\n",
      "Number of masks after deletion: 1900\n"
     ]
    }
   ],
   "source": [
    "# Count number of masks before and after recursively (check values, not keys)\n",
    "def count_masks(masks):\n",
    "    count = 0\n",
    "    for file_name in masks:\n",
    "        count += len(masks[file_name])\n",
    "    return count\n",
    "\n",
    "print(f'Number of masks before deletion: {count_masks(masks)}\\nNumber of masks after deletion: {count_masks(masks_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = masks_valid\n",
    "gt_masks = gt_masks_valid\n",
    "gt_ranks = gt_ranks_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to .h5\n",
    "import h5py\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/masks_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in masks:\n",
    "        for mask in masks[file_name]:\n",
    "            hf.create_dataset(f'{file_name}/{mask}', data=masks[file_name][mask])\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/gt_masks_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in gt_masks:\n",
    "        for mask in gt_masks[file_name]:\n",
    "            hf.create_dataset(f'{file_name}/{mask}', data=gt_masks[file_name][mask])\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/gt_ranks_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in gt_ranks:\n",
    "        gt_ranks[file_name] = np.array(list(gt_ranks[file_name].values()))\n",
    "        hf.create_dataset(f'{file_name}', data=gt_ranks[file_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from .h5\n",
    "import h5py\n",
    "\n",
    "masks = {}\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/masks_' + str(experiment) + '.h5', 'r') as hf:\n",
    "    for file_name in hf:\n",
    "        masks[file_name] = {}\n",
    "        for mask in hf[file_name]:\n",
    "            masks[file_name][mask] = hf[f'{file_name}/{mask}'][:]\n",
    "\n",
    "gt_masks = {}\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/gt_masks_' + str(experiment) + '.h5', 'r') as hf:\n",
    "    for file_name in hf:\n",
    "        gt_masks[file_name] = {}\n",
    "        for mask in hf[file_name]:\n",
    "            gt_masks[file_name][mask] = hf[f'{file_name}/{mask}'][:]\n",
    "\n",
    "gt_ranks = {}\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/gt_ranks_' + str(experiment) + '.h5', 'r') as hf:\n",
    "    for file_name in hf:\n",
    "        gt_ranks[file_name] = hf[file_name][:]\n",
    "\n",
    "        # Convert list into dict with keys as integers\n",
    "        gt_ranks[file_name] = {i: rank for i, rank in enumerate(gt_ranks[file_name])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saliency Maps/Heatmaps/Rankings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DeepGaze IIE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/matthewkenely/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "Using cache found in /home/matthewkenely/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "/home/matthewkenely/Programming/Assignments/ICT3909 Final Year Project in Artificial Intelligence/ICT3909/optimisations/saliency-generator/saraRC1.py:191: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  image_batch = torch.tensor([img.transpose(2, 0, 1) for img in images]).to(DEVICE)\n",
      "/home/matthewkenely/Programming/Assignments/ICT3909 Final Year Project in Artificial Intelligence/ICT3909/optimisations/saliency-generator/saraRC1.py:277: RuntimeWarning: divide by zero encountered in log\n",
      "  sum = np.log(sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 of 63 complete\n",
      "Batch 2 of 63 complete\n",
      "Batch 3 of 63 complete\n",
      "Batch 4 of 63 complete\n",
      "Batch 5 of 63 complete\n",
      "Batch 6 of 63 complete\n",
      "Batch 7 of 63 complete\n",
      "Batch 8 of 63 complete\n",
      "Batch 9 of 63 complete\n",
      "Batch 10 of 63 complete\n",
      "Batch 11 of 63 complete\n",
      "Batch 12 of 63 complete\n",
      "Batch 13 of 63 complete\n",
      "Batch 14 of 63 complete\n",
      "Batch 15 of 63 complete\n",
      "Batch 16 of 63 complete\n",
      "Batch 17 of 63 complete\n",
      "Batch 18 of 63 complete\n",
      "Batch 19 of 63 complete\n",
      "Batch 20 of 63 complete\n",
      "Batch 21 of 63 complete\n",
      "Batch 22 of 63 complete\n",
      "Batch 23 of 63 complete\n",
      "Batch 24 of 63 complete\n",
      "Batch 25 of 63 complete\n",
      "Batch 26 of 63 complete\n",
      "Batch 27 of 63 complete\n",
      "Batch 28 of 63 complete\n",
      "Batch 29 of 63 complete\n",
      "Batch 30 of 63 complete\n",
      "Batch 31 of 63 complete\n",
      "Batch 32 of 63 complete\n",
      "Batch 33 of 63 complete\n",
      "Batch 34 of 63 complete\n",
      "Batch 35 of 63 complete\n",
      "Batch 36 of 63 complete\n",
      "Batch 37 of 63 complete\n",
      "Batch 38 of 63 complete\n",
      "Batch 39 of 63 complete\n",
      "Batch 40 of 63 complete\n",
      "Batch 41 of 63 complete\n",
      "Batch 42 of 63 complete\n",
      "Batch 43 of 63 complete\n",
      "Batch 44 of 63 complete\n",
      "Batch 45 of 63 complete\n",
      "Batch 46 of 63 complete\n",
      "Batch 47 of 63 complete\n",
      "Batch 48 of 63 complete\n",
      "Batch 49 of 63 complete\n",
      "Batch 50 of 63 complete\n",
      "Batch 51 of 63 complete\n",
      "Batch 52 of 63 complete\n",
      "Batch 53 of 63 complete\n",
      "Batch 54 of 63 complete\n",
      "Batch 55 of 63 complete\n",
      "Batch 56 of 63 complete\n",
      "Batch 57 of 63 complete\n",
      "Batch 58 of 63 complete\n",
      "Batch 59 of 63 complete\n",
      "Batch 60 of 63 complete\n",
      "Batch 61 of 63 complete\n",
      "Batch 62 of 63 complete\n",
      "Batch 63 of 63 complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time\n",
    "import deepgaze_pytorch\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "plt.figure()\n",
    "plt.tight_layout()\n",
    "\n",
    "generators = ['deepgaze']\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "DEVICE = 'cuda'  # Use GPU if available\n",
    "model = deepgaze_pytorch.DeepGazeIIE(pretrained=True).to(DEVICE)\n",
    "\n",
    "# Split the images with masks into batches with the image names as keys and the images as values\n",
    "image_batches = [{k: imgs[k] for k in list(masks.keys())[i:i+BATCH_SIZE]} for i in range(0, len(masks), BATCH_SIZE)]\n",
    "\n",
    "seg_dim = 9\n",
    "saliency_maps = {}\n",
    "sara_heatmaps = {}\n",
    "sara_lists = {}\n",
    "\n",
    "sara.WEIGHTS = (1, 1, 1, 1)\n",
    "\n",
    "c = 0\n",
    "\n",
    "for batch in image_batches:\n",
    "    start = time()\n",
    "\n",
    "    for im in batch:\n",
    "        if im not in saliency_maps:\n",
    "            saliency_maps[im] = {}\n",
    "            sara_heatmaps[im] = {}\n",
    "            sara_lists[im] = {}\n",
    "\n",
    "        \n",
    "\n",
    "    for generator in generators:\n",
    "        temp_saliency_maps = sara.return_saliency_batch(batch.values(), generator=generator, deepgaze_model=model, DEVICE=DEVICE, BATCH_SIZE=BATCH_SIZE)\n",
    "        \n",
    "    sara.reset()\n",
    "\n",
    "    for i, im in enumerate(batch):\n",
    "        saliency_maps[im][generator] = temp_saliency_maps[i]\n",
    "        sara_heatmaps[im][generator], sara_lists[im][generator] = sara.return_sara(cv2.cvtColor(imgs[im].copy(), cv2.COLOR_RGB2BGR), seg_dim, saliency_map=saliency_maps[im][generator])\n",
    "        # plt.figure()\n",
    "        # plt.subplot(121)\n",
    "        # plt.imshow(saliency_maps[im][generator], cmap='gray')\n",
    "        # plt.subplot(122)\n",
    "        # plt.imshow(cv2.cvtColor(sara_heatmaps[im][generator], cv2.COLOR_BGR2RGB))\n",
    "        # plt.show()\n",
    "        # sara.reset()\n",
    "\n",
    "    c += 1\n",
    "\n",
    "    print(f'Batch {c} of {len(image_batches)} complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Old SaRa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time\n",
    "import deepgaze_pytorch\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "plt.figure()\n",
    "plt.tight_layout()\n",
    "\n",
    "generators = ['itti']\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "DEVICE = 'cpu'  # Use GPU if available\n",
    "# model = deepgaze_pytorch.DeepGazeIIE(pretrained=True).to(DEVICE)\n",
    "\n",
    "# Split the images with masks into batches with the image names as keys and the images as values\n",
    "# image_batches = [{k: imgs[k] for k in list(masks.keys())[i:i+BATCH_SIZE]} for i in range(0, len(masks), BATCH_SIZE)]\n",
    "\n",
    "seg_dim = 9\n",
    "saliency_maps = {}\n",
    "sara_heatmaps = {}\n",
    "sara_lists = {}\n",
    "\n",
    "sara.WEIGHTS = (1, 1, 1, 1)\n",
    "\n",
    "c = 0\n",
    "\n",
    "for im in imgs:\n",
    "    start = time()\n",
    "\n",
    "    if im not in saliency_maps:\n",
    "        saliency_maps[im] = {}\n",
    "        sara_heatmaps[im] = {}\n",
    "        sara_lists[im] = {}\n",
    "\n",
    "    for generator in generators:\n",
    "        # saliency_maps[im][generator] = sara.return_saliency(imgs[im], generator=generator)\n",
    "        # sara_heatmaps[im][generator], sara_lists[im][generator] = sara.return_sara(cv2.cvtColor(imgs[im].copy(), cv2.COLOR_RGB2BGR), seg_dim, saliency_map=saliency_maps[im][generator])\n",
    "        sara_heatmaps[im][generator], sara_lists[im][generator] = sara_old.returnSARA(cv2.cvtColor(imgs[im].copy(), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "    c += 1\n",
    "\n",
    "    # print(f'Image {c} of {len(imgs)} complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = True\n",
    "\n",
    "if old:\n",
    "    subdirectory = 'old'\n",
    "else:\n",
    "    subdirectory = 'new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to .h5\n",
    "import h5py\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/saliency_maps_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in saliency_maps:\n",
    "        for generator in saliency_maps[file_name]:\n",
    "            hf.create_dataset(f'{file_name}/{generator}', data=saliency_maps[file_name][generator])\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sara_heatmaps_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in sara_heatmaps:\n",
    "        for generator in sara_heatmaps[file_name]:\n",
    "            hf.create_dataset(f'{file_name}/{generator}', data=sara_heatmaps[file_name][generator])\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sara_lists_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in sara_lists:\n",
    "        for generator in sara_lists[file_name]:\n",
    "            hf.create_dataset(f'{file_name}/{generator}', data=sara_lists[file_name][generator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from .h5\n",
    "import h5py\n",
    "\n",
    "saliency_maps = {}\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/saliency_maps_' + str(experiment) + '.h5', 'r') as hf:\n",
    "    for file_name in hf:\n",
    "        saliency_maps[file_name] = {}\n",
    "        for generator in hf[file_name]:\n",
    "            saliency_maps[file_name][generator] = hf[f'{file_name}/{generator}'][:]\n",
    "\n",
    "sara_heatmaps = {}\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sara_heatmaps_' + str(experiment) + '.h5', 'r') as hf:\n",
    "    for file_name in hf:\n",
    "        sara_heatmaps[file_name] = {}\n",
    "        for generator in hf[file_name]:\n",
    "            sara_heatmaps[file_name][generator] = hf[f'{file_name}/{generator}'][:]\n",
    "\n",
    "sara_lists = {}\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sara_lists_' + str(experiment) + '.h5', 'r') as hf:\n",
    "    for file_name in hf:\n",
    "        sara_lists[file_name] = {}\n",
    "        for generator in hf[file_name]:\n",
    "            sara_lists[file_name][generator] = hf[f'{file_name}/{generator}'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Mask Ranking</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_coordinates(index, seg_dim, im_size):\n",
    "    '''\n",
    "    Given an index and a shape, this function returns the corresponding coordinates.\n",
    "    '''\n",
    "\n",
    "    x1 = int((index % seg_dim) * (im_size[1] / seg_dim))\n",
    "    y1 = int((index // seg_dim) * (im_size[0] / seg_dim))\n",
    "\n",
    "    x2 = int(x1 + (im_size[1] / seg_dim))\n",
    "    y2 = int(y1 + (im_size[0] / seg_dim))\n",
    "    \n",
    "    return (x1, y1, x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each segment, check which mask falls under that segment using MRn = rank(Gi); (Gi interesect Mn) > T\n",
    "mask_segments = {}\n",
    "\n",
    "if old:\n",
    "    generator = 'itti'\n",
    "else:\n",
    "    generator = 'deepgaze'\n",
    "    \n",
    "\n",
    "for sara_list in sara_lists:\n",
    "    for segment in sara_lists[sara_list][generator]:\n",
    "        if sara_list not in mask_segments:\n",
    "            mask_segments[sara_list] = {}\n",
    "\n",
    "        # Convert index to coordinates, extract segment from heatmap\n",
    "        shape = sara_heatmaps[sara_list][generator].shape[0:2]\n",
    "        if old:\n",
    "            x1, y1, x2, y2 = index_to_coordinates(segment[0], seg_dim, shape)\n",
    "        else:\n",
    "            x1, y1, x2, y2 = index_to_coordinates(segment[6], seg_dim, shape)\n",
    "\n",
    "        # print(x1, y1, x2, y2)\n",
    "\n",
    "        if sara_list in list(masks.keys()):\n",
    "            # Find the best matching mask\n",
    "            best_iou = 0\n",
    "            best_mask = None\n",
    "            \n",
    "            for m in masks[sara_list]:\n",
    "                if m not in mask_segments[sara_list]:\n",
    "                    mask_segments[sara_list][m] = []\n",
    "\n",
    "                # Extract mask from masks\n",
    "                mask = masks[sara_list][m][y1:y2, x1:x2]\n",
    "\n",
    "                # Calculate intersection over union\n",
    "                intersection = np.sum(mask > 0)\n",
    "                union = np.sum(mask > 0) + np.sum(mask == 0)\n",
    "                iou = intersection / union\n",
    "\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_mask = m\n",
    "                elif iou > 0:\n",
    "                    mask_segments[sara_list][m].append(segment)\n",
    "\n",
    "            if best_mask is not None:\n",
    "                mask_segments[sara_list][best_mask].append(segment)\n",
    "\n",
    "\n",
    "            # Check the masks which are not best_mask, if they will not be empty after removing the current segment, do so\n",
    "            for m in mask_segments[sara_list]:\n",
    "                if m != best_mask:\n",
    "                    if len(mask_segments[sara_list][m]) > 1:\n",
    "                        mask_segments[sara_list][m].pop()\n",
    "\n",
    "        # Sort mask_segments[sara_list]\n",
    "\n",
    "\n",
    "    # If there are empty masks, remove them and remove the corresponding mask in gt_ranks and gt_masks\n",
    "    for m in list(mask_segments[sara_list].keys()):\n",
    "        if len(mask_segments[sara_list][m]) == 0:\n",
    "            del mask_segments[sara_list][m]\n",
    "            del gt_masks[sara_list][m]\n",
    "\n",
    "            # Find index of key\n",
    "            for i, key in enumerate(gt_ranks[sara_list]):\n",
    "                if key == m:\n",
    "                    break\n",
    "            # del gt_ranks[sara_list][i]\n",
    "            gt_ranks[sara_list].pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each mask, find the segment with the lowest rank\n",
    "mask_segments_min = {}\n",
    "\n",
    "for sara_list in mask_segments:\n",
    "    for m in mask_segments[sara_list]:\n",
    "        # mask_segments_min[sara_list][m] = min(mask_segments[sara_list][m], key=lambda x: x[1])[0]\n",
    "        if sara_list not in mask_segments_min:\n",
    "            mask_segments_min[sara_list] = {}\n",
    "        \n",
    "        if old:\n",
    "            mask_segments_min[sara_list][m] = min(mask_segments[sara_list][m], key=lambda x: x[1])\n",
    "        else:\n",
    "            mask_segments_min[sara_list][m] = min(mask_segments[sara_list][m], key=lambda x: x[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ranks = {}\n",
    "\n",
    "for sara_list in mask_segments_min:\n",
    "    mask_ranks[sara_list] = {}\n",
    "    # Extract the ranks and sort them by the third value in each tuple\n",
    "    sorted_ranks = sorted(mask_segments_min[sara_list].items(), key=lambda x: x[1][1])\n",
    "\n",
    "    for i in range(len(sorted_ranks)):\n",
    "        mask_ranks[sara_list][sorted_ranks[i][0]] = i\n",
    "\n",
    "    # Sort mask_ranks[sara_list] by object\n",
    "    mask_ranks[sara_list] = {k: v for k, v in sorted(mask_ranks[sara_list].items(), key=lambda item: item[0])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Spearman Correlation (Metric for Ranks)</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_spr(spr_value):\n",
    "    r_min = -1\n",
    "    r_max = 1\n",
    "\n",
    "    norm_spr = (spr_value - r_min) / (r_max - r_min)\n",
    "\n",
    "    return norm_spr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SPR: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthewkenely/anaconda3/envs/sara/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/matthewkenely/anaconda3/envs/sara/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as sc\n",
    "\n",
    "all_spr = []\n",
    "\n",
    "for sara_list in mask_ranks:\n",
    "    # print(f'PR: {list(mask_ranks[sara_list].values())}\\nGT: {list(gt_ranks[sara_list].values())}')\n",
    "    spr = sc.spearmanr(list(mask_ranks[sara_list].values()), list(gt_ranks[sara_list].values())[:len(list(mask_ranks[sara_list].values()))])\n",
    "    if not np.isnan(spr.correlation):\n",
    "        all_spr.append(get_norm_spr(spr.correlation))\n",
    "        # print(f'SPR: {spr.correlation}')\n",
    "\n",
    "print(f'Average SPR: {np.mean(all_spr)}')\n",
    "\n",
    "# Plot sprs\n",
    "plt.figure()\n",
    "plt.plot(all_spr, marker='o', linestyle='None')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_spr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary: image: spr\n",
    "sprs = {}\n",
    "\n",
    "for sara_list in mask_ranks:\n",
    "    spr = sc.spearmanr(list(mask_ranks[sara_list].values()), list(gt_ranks[sara_list].values())[:len(list(mask_ranks[sara_list].values()))])\n",
    "    if not np.isnan(spr.correlation):\n",
    "        sprs[sara_list] = get_norm_spr(spr.correlation)\n",
    "\n",
    "# Sort sprs by value descending\n",
    "sprs = {k: v for k, v in sorted(sprs.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "len_ = len(masks)\n",
    "\n",
    "# Save len_ in txt file\n",
    "with open('./experiments/' + str(experiment) + '/len_' + str(experiment) + '.txt', 'w') as f:\n",
    "    f.write(str(len_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all sprs with value > 0.7\n",
    "sprs_07 = {k: v for k, v in sprs.items() if v > 0.7}\n",
    "\n",
    "for sara_list in mask_segments_min:\n",
    "    mask_ranks[sara_list] = {}\n",
    "    # Extract the ranks and sort them by the third value in each tuple\n",
    "    sorted_ranks = sorted(mask_segments_min[sara_list].items(), key=lambda x: x[1][1])\n",
    "\n",
    "    for i in range(len(sorted_ranks)):\n",
    "        mask_ranks[sara_list][sorted_ranks[i][0]] = i\n",
    "\n",
    "    # Sort mask_ranks[sara_list] by object\n",
    "    mask_ranks[sara_list] = {k: v for k, v in sorted(mask_ranks[sara_list].items(), key=lambda item: item[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to .h5\n",
    "import h5py\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sprs_' + str(experiment) + '.h5', 'w') as hf:\n",
    "    for file_name in sprs:\n",
    "        hf.create_dataset(f'{file_name}', data=sprs[file_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Illegal slicing argument for scalar dataspace",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a7be87bc0aeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./experiments/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/sprs_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msprs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Convert list into dict with keys as integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sara/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m             \u001b[0mselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sara/lib/python3.6/site-packages/h5py/_hl/selections2.py\u001b[0m in \u001b[0;36mselect_read\u001b[0;34m(fspace, args)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \"\"\"\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mScalarReadSelection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sara/lib/python3.6/site-packages/h5py/_hl/selections2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fspace, args)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Illegal slicing argument for scalar dataspace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCALAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Illegal slicing argument for scalar dataspace"
     ]
    }
   ],
   "source": [
    "# Load from .h5\n",
    "import h5py\n",
    "\n",
    "sprs = {}\n",
    "\n",
    "with h5py.File('./experiments/' + str(experiment) + '/' + subdirectory + '/sprs_' + str(experiment) + '.h5', 'r') as hf:\n",
    "    for file_name in hf:\n",
    "        sprs[file_name] = hf[file_name][:]\n",
    "\n",
    "        # Convert list into dict with keys as integers\n",
    "        sprs[file_name] = {i: spr for i, spr in enumerate(sprs[file_name])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Mean Absolute Error</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(pred, gt):\n",
    "    return np.mean(np.abs(pred - gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average /mae: 0.0\n"
     ]
    }
   ],
   "source": [
    "all_mae = 0\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "for sara_list in masks:\n",
    "    for mask in masks[sara_list]:\n",
    "        # print(masks[sara_list][mask] - gt_masks[sara_list][mask])\n",
    "        pred = masks[sara_list][mask]\n",
    "        pred = np.array(pred, dtype=np.uint8)\n",
    "        pred = cv2.threshold(pred, 0.5, 1, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        gt = gt_masks[sara_list][mask]\n",
    "        gt = np.array(gt, dtype=np.uint8)\n",
    "        gt = cv2.threshold(gt, 0.5, 1, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        temp_mae = mae(pred, gt)\n",
    "\n",
    "        # Print iou\n",
    "        intersection = np.logical_and(pred, gt)\n",
    "        union = np.logical_or(pred, gt)\n",
    "        iou_score = np.sum(intersection) / np.sum(union)\n",
    "        # print(f'IOU: {iou_score}')\n",
    "\n",
    "        # plt.figure()\n",
    "        # plt.subplot(131)\n",
    "        # plt.imshow(pred)\n",
    "        # plt.subplot(132)\n",
    "        # plt.imshow(gt)\n",
    "        # plt.subplot(133)\n",
    "        # plt.imshow(pred - gt)\n",
    "        # plt.show()\n",
    "        all_mae += temp_mae\n",
    "        # print()\n",
    "        # break\n",
    "\n",
    "print(f'Average /mae: {all_mae / len(masks)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('coco')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8985379cc137063dd0de237b7b7b8346889aff6edaf8a0ed61b320fa88bc9a9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
